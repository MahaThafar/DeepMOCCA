{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8825827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import rdflib as rl\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pycox.models import CoxPH\n",
    "from pycox.evaluation import EvalSurv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GraphConv, SAGPooling\n",
    "from torch_geometric.nn import global_max_pool as gmp\n",
    "import click as ck\n",
    "import gzip\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f1bb4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CANCER_SUBTYPES = [\n",
    "    [0,12,7,14,4,1,6,2,3],\n",
    "    [4],\n",
    "    [5,4,14,6],\n",
    "    [6,4,12,7],\n",
    "    [4],\n",
    "    [6,4,12,7],\n",
    "    [8],\n",
    "    [6,4,12],\n",
    "    [9],\n",
    "    [6],\n",
    "    [4],\n",
    "    [4],\n",
    "    [4],\n",
    "    [10],\n",
    "    [9],\n",
    "    [4],\n",
    "    [4,11,12],\n",
    "    [6],\n",
    "    [13],\n",
    "    [12],\n",
    "    [0,4,12,14],\n",
    "    [15],\n",
    "    [4,0,12],\n",
    "    [4,12],\n",
    "    [16,17,18,19,20],\n",
    "    [20],\n",
    "    [4,12],\n",
    "    [22],\n",
    "    [4,14],\n",
    "    [23],\n",
    "    [4,12,14],\n",
    "    [24],\n",
    "    [21]\n",
    "]\n",
    "\n",
    "CELL_TYPES = [\n",
    "    0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 3, 0, 0, 4, 2, 0,\n",
    "    0, 0, 5, 0, 0, 6, 0, 0, 7, 8, 0, 9, 0, 0, 0, 0,\n",
    "    8]\n",
    "\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, edge_index):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.edge_index = edge_index\n",
    "        self.conv1 = GCNConv(6,64)\n",
    "        self.pool1 = SAGPooling(64, ratio=0.70, GNN=GCNConv)\n",
    "        self.conv2 = GCNConv(64,32)\n",
    "        self.fc1 = nn.Linear(32,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, data):\n",
    "        batch_size = data.shape[0]\n",
    "        x = data[:, :103116]\n",
    "        metadata = data[:, 103116:]\n",
    "        input_size = 17186\n",
    "        x = x.reshape(-1, 6)\n",
    "        batches = []\n",
    "        for i in range(batch_size):\n",
    "            tr = torch.ones(input_size, dtype=torch.int64) * i\n",
    "            batches.append(tr)\n",
    "        batch = torch.cat(batches, 0).to(device)\n",
    "        x = F.relu(self.conv1(x, self.edge_index))\n",
    "        x, edge_index, _, batch, perm, score = self.pool1(x, self.edge_index, None, batch)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = gmp(x, batch)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7dc61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pre-processed methylation data\n",
    "def myth_data(fname, seen, d, dic):\n",
    "    f=open(fname)\n",
    "    line=f.readlines()\n",
    "    f.close()\n",
    "    output=[[0,0,0,0,0,0] for j in range(len(seen)+1)]\n",
    "    for l in line:\n",
    "        temp=[]\n",
    "        trans,myth=l.split('\\t')\n",
    "        temp=trans.split(';')\n",
    "        myth=float(myth)\n",
    "        for x in temp:\n",
    "            index=x.find('.')\n",
    "            if index<1:\n",
    "                index=len(x)\n",
    "            x=x[:index]\n",
    "            if x in d:\n",
    "                gen = d[x]\n",
    "            if gen in dic:\n",
    "                for p in dic[gen]:\n",
    "                    if p in seen:\n",
    "                        output[seen[p]][0]=myth\n",
    "    return output\n",
    "\n",
    "# Import the pre-processed gene expression files\n",
    "\n",
    "def get_data(expname,diffexpname,diffmethyname,cnvname,vcfname,output, seen, dic):\n",
    "    f=gzip.open(expname,'rt')\n",
    "    line=f.readlines()\n",
    "    f.close()\n",
    "    for l in line:\n",
    "        gene,exp=l.split('\\t')\n",
    "        prev=gene\n",
    "        index=gene.find('.')\n",
    "        if index<1:\n",
    "            index=len(gene)\n",
    "        gene=gene[:index]\n",
    "        exp=float(exp)\n",
    "        if gene in dic:\n",
    "            for p in dic[gene]:\n",
    "                if p in seen:\n",
    "                    output[seen[p]][1]=exp\n",
    "\n",
    "    # Import the pre-processed differential gene expression files            \n",
    "    f=gzip.open(diffexpname,'rt')\n",
    "    line=f.readlines()\n",
    "    f.close()    \n",
    "    for l in line:\n",
    "        gene,diffexp=l.split('\\t')\n",
    "        prev=gene\n",
    "        index=gene.find('.')\n",
    "        if index<1:\n",
    "            index=len(gene)\n",
    "        gene=gene[:index]\n",
    "        diffexp=float(diffexp)\n",
    "        if gene in seen:\n",
    "            output[seen[gene]][2]=diffexp\n",
    "\n",
    "    # Import the pre-processed differential methylation files           \n",
    "    f=open(diffmethyname)\n",
    "    line=f.readlines()\n",
    "    f.close()    \n",
    "    for l in line:\n",
    "        gene,diffmethy=l.split('\\t')\n",
    "        prev=gene\n",
    "        index=gene.find('.')\n",
    "        if index<1:\n",
    "            index=len(gene)\n",
    "        gene=gene[:index]\n",
    "        diffmethy=float(diffmethy)\n",
    "        if gene in seen:\n",
    "            output[seen[gene]][3]=diffmethy\n",
    "    # Import the pre-processed CNV files\n",
    "    f=open(cnvname)\n",
    "    line=f.readlines()\n",
    "    f.close()    \n",
    "    for l in line:\n",
    "        gene,cnv=l.split('\\t')\n",
    "        prev=gene\n",
    "        index=gene.find('.')\n",
    "        if index<1:\n",
    "            index=len(gene)\n",
    "        gene=gene[:index]\n",
    "        cnv=float(cnv)\n",
    "        if gene in dic:\n",
    "            for p in dic[gene]:\n",
    "                if p in seen:\n",
    "                    output[seen[p]][4]=cnv                        \n",
    "    # Import the pre-processed VCF files          \n",
    "    f=open(vcfname)\n",
    "    line=f.readlines()\n",
    "    f.close()    \n",
    "    for l in line:\n",
    "        gene,score=l.split('\\t')\n",
    "        score=float(score)\n",
    "        if gene in dic:\n",
    "            for p in dic[gene]:\n",
    "                if p in seen:\n",
    "                    output[seen[p]][5]=score\n",
    "                \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3446200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ck.command()\n",
    "# @ck.option('--cancer-type', '-ct', default=0, help='Cancer type index (0-32)')\n",
    "# @ck.option('--anatomical-location', '-al', default=0, help='Anatomical location index (0-51)')\n",
    "cancer_type = 0\n",
    "anatomical_location = 0\n",
    "data_root = 'data_folder/'\n",
    "# def main(cancer_type, anatomical_location):\n",
    "\n",
    "# Import the RDF graph for PPI network\n",
    "f = open('seen.pkl','rb')\n",
    "seen = pickle.load(f)\n",
    "f.close()\n",
    "#####################\n",
    "\n",
    "f = open('ei.pkl','rb')\n",
    "ei = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "global device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "cancer_type_vector = np.zeros((33,), dtype=np.float32)\n",
    "cancer_type_vector[cancer_type] = 1\n",
    "\n",
    "cancer_subtype_vector = np.zeros((25,), dtype=np.float32)\n",
    "for i in CANCER_SUBTYPES[cancer_type]:\n",
    "    cancer_subtype_vector[i] = 1\n",
    "\n",
    "anatomical_location_vector = np.zeros((52,), dtype=np.float32)\n",
    "anatomical_location_vector[anatomical_location] = 1\n",
    "cell_type_vector = np.zeros((10,), dtype=np.float32)\n",
    "cell_type_vector[CELL_TYPES[cancer_type]] = 1\n",
    "\n",
    "pt_tensor_cancer_type = torch.FloatTensor(cancer_type_vector).to(device)\n",
    "pt_tensor_cancer_subtype = torch.FloatTensor(cancer_subtype_vector).to(device)\n",
    "pt_tensor_anatomical_location = torch.FloatTensor(anatomical_location_vector).to(device)\n",
    "pt_tensor_cell_type = torch.FloatTensor(cell_type_vector).to(device)\n",
    "edge_index = torch.LongTensor(ei).to(device)\n",
    "\n",
    "# Import a dictionary that maps protiens to their coresponding genes by Ensembl database\n",
    "f = open('ens_dic.pkl','rb')\n",
    "dicty = pickle.load(f)\n",
    "f.close()\n",
    "dic = {}\n",
    "for d in dicty:\n",
    "    key=dicty[d]\n",
    "    if key not in dic:\n",
    "        dic[key]={}\n",
    "    dic[key][d]=1\n",
    "\n",
    "# Build a dictionary from ENSG -- ENST\n",
    "d = {}\n",
    "with open(data_root+'prot_names1.txt') as f:\n",
    "    for line in f:\n",
    "        tok = line.split()\n",
    "        d[tok[1]] = tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c17123a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...... Done\n"
     ]
    }
   ],
   "source": [
    "clin = [] # for clinical data (i.e. number of days to survive, days to death for dead patients and days to last followup for alive patients)\n",
    "feat_vecs = [] # list of lists ([[patient1],[patient2],.....[patientN]]) -- [patientX] = [gene_expression_value, diff_gene_expression_value, methylation_value, diff_methylation_value, VCF_value, CNV_value]\n",
    "suv_time = [] # list that include wheather a patient is alive or dead (i.e. 0 for dead and 1 for alive)\n",
    "for i in range(len(can_types)):\n",
    "    # file that contain patients ID with their coressponding 6 differnt files names (i.e. files names for gene_expression, diff_gene_expression, methylation, diff_methylation, VCF and CNV)\n",
    "    f = open(data_root + can_types[i] + '.txt')\n",
    "    lines = f.read().splitlines()\n",
    "    f.close()\n",
    "    lines = lines[1:]\n",
    "    count = 0\n",
    "    feat_vecs = np.zeros((len(lines), 17186 * 6), dtype=np.float32)\n",
    "    i = 0\n",
    "    for l in lines:\n",
    "        l = l.split('\\t')\n",
    "        clinical_file = l[6]\n",
    "        surv_file = l[2]\n",
    "        myth_file = data_root + 'myth/' + l[3]\n",
    "        diff_myth_file = data_root + 'diff_myth/' + l[1]\n",
    "        exp_norm_file = data_root + 'exp_count/' + l[-1]\n",
    "        diff_exp_norm_file = data_root + 'diff_exp/' + l[0]\n",
    "        cnv_file = data_root + 'cnv/' + l[4] + '.txt'\n",
    "        vcf_file = data_root + 'vcf/' + 'OutputAnnoFile_' + l[5] + '.hg38_multianno.txt.dat'\n",
    "        # Check if all 6 files are exist for a patient (that's because for some patients, their survival time not reported)\n",
    "        all_files = [\n",
    "            myth_file, diff_exp_norm_file, diff_myth_file,\n",
    "            exp_norm_file, cnv_file, vcf_file]\n",
    "        for fname in all_files:\n",
    "            if not os.path.exists(fname):\n",
    "                print('File ' + fname + ' does not exist!')\n",
    "                sys.exit(1)\n",
    "        clin.append(clinical_file)\n",
    "        suv_time.append(surv_file)\n",
    "        temp_myth=myth_data(myth_file, seen, d, dic)\n",
    "        vec = np.array(\n",
    "            get_data(\n",
    "                exp_norm_file, diff_exp_norm_file, diff_myth_file,\n",
    "                cnv_file, vcf_file, temp_myth, seen, dic), dtype=np.float32)\n",
    "        vec = vec.flatten()\n",
    "#         vec = np.concatenate([\n",
    "#             vec, cancer_type_vector, cancer_subtype_vector,\n",
    "#             anatomical_location_vector, cell_type_vector])\n",
    "        feat_vecs[i, :] = vec\n",
    "        i += 1\n",
    "print(\"Loading data ...... Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bcd504f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TCGA-ACC\n",
      "0.7489348484 [0.7368256894-0.7556322619]\n",
      "TCGA-BLCA\n",
      "0.7798174935 [0.7587509612-0.7942539644]\n",
      "TCGA-BRCA\n",
      "0.8734027557 [0.8621480621-0.8848587343]\n",
      "TCGA-CESC\n",
      "0.8487463528 [0.8391145836-0.8550207046]\n",
      "TCGA-CHOL\n",
      "0.6932485293 [0.6804234098-0.7062482649]\n",
      "TCGA-COAD\n",
      "0.8729847836 [0.8524897644-0.8897047926]\n",
      "TCGA-DLBC\n",
      "0.7587834962 [0.7498327992-0.7666218624]\n",
      "TCGA-ESCA\n",
      "0.8078877658 [0.7883235775-0.8184369821]\n",
      "TCGA-GBM\n",
      "0.8572748352 [0.8408375373-0.8641436216]\n",
      "TCGA-HNSC\n",
      "0.8880673492 [0.8672468637-0.8954375793]\n",
      "TCGA-KICH\n",
      "0.7794687067 [0.7564782378-0.7861784922]\n",
      "TCGA-KIRC\n",
      "0.8724742832 [0.8546383291-0.8805036383]\n",
      "TCGA-KIRP\n",
      "0.8189732621 [0.8065238913-0.8256292189]\n",
      "TCGA-LAML\n",
      "0.7224238901 [0.7078862391-0.7352293275]\n",
      "TCGA-LGG\n",
      "0.7672532943 [0.7539073228-0.7726863292]\n",
      "TCGA-LIHC\n",
      "0.7503882039 [0.7441640187-0.7684799273]\n",
      "TCGA-LUAD\n",
      "0.8852273945 [0.8625893293-0.8946007382]\n",
      "TCGA-LUSC\n",
      "0.8756683279 [0.8592683492-0.8835728929]\n",
      "TCGA-MESO\n",
      "0.7536643926 [0.7482847297-0.7719187215]\n",
      "TCGA-OV\n",
      "0.8659895345 [0.8528008389-0.8701129728]\n",
      "TCGA-PAAD\n",
      "0.7363647298 [0.7266747929-0.7428126792]\n",
      "TCGA-PCPG\n",
      "0.8736892649 [0.8656098732-0.8839272934]\n",
      "TCGA-PRAD\n",
      "0.7326743972 [0.7272079382-0.7453389317]\n",
      "TCGA-READ\n",
      "0.7479862474 [0.7389233873-0.7536475839]\n",
      "TCGA-SARC\n",
      "0.8784746293 [0.8648908483-0.8843643927]\n",
      "TCGA-SKCM\n",
      "0.7426847390 [0.7369746296-0.7532547443]\n",
      "TCGA-STAD\n",
      "0.8507253822 [0.8462257346-0.8661353648]\n",
      "TCGA-TGCT\n",
      "0.7074666383 [0.6804784778-0.7254854077]\n",
      "TCGA-THCA\n",
      "0.8534674382 [0.8468732341-0.8715308904]\n",
      "TCGA-THYM\n",
      "0.7158677849 [0.7094888524-0.7256752631]\n",
      "TCGA-UCEC\n",
      "0.7965118161 [0.7745456502-0.8167178545]\n",
      "TCGA-UCS\n",
      "0.6746679628 [0.6684t67213-0.6832194560]\n",
      "TCGA-UVM\n",
      "0.7647563735 [0.7526786335-0.7709087023]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "labels_days = []\n",
    "labels_surv = []\n",
    "for days, surv in zip(clin, suv_time):\n",
    "    labels_days.append(float(days))\n",
    "    labels_surv.append(float(surv))\n",
    "\n",
    "# Train by batch\n",
    "dataset = feat_vecs\n",
    "labels_days = np.array(labels_days)\n",
    "labels_surv = np.array(labels_surv)\n",
    "\n",
    "censored_index = []\n",
    "uncensored_index = []\n",
    "for i in range(len(dataset)):\n",
    "    if labels_surv[i] == 1:\n",
    "        censored_index.append(i)\n",
    "    else:\n",
    "        uncensored_index.append(i)\n",
    "model = CoxPH(MyNet(edge_index).to(device), tt.optim.Adam(0.0001))\n",
    "\n",
    "censored_index = np.array(censored_index)\n",
    "uncensored_index = np.array(uncensored_index)\n",
    "\n",
    "names = [\"TCGA-ACC\",\"TCGA-BLCA\",\"TCGA-BRCA\",\"TCGA-CESC\",\"TCGA-CHOL\",\"TCGA-COAD\",\"TCGA-DLBC\",\"TCGA-ESCA\",\"TCGA-GBM\",\"TCGA-HNSC\",\"TCGA-KICH\",\"TCGA-KIRC\",\"TCGA-KIRP\",\"TCGA-LAML\",\"TCGA-LGG\",\"TCGA-LIHC\",\"TCGA-LUAD\",\"TCGA-LUSC\",\"TCGA-MESO\",\"TCGA-OV\",\"TCGA-PAAD\",\"TCGA-PCPG\",\"TCGA-PRAD\",\"TCGA-READ\",\"TCGA-SARC\",\"TCGA-SKCM\",\"TCGA-STAD\",\"TCGA-TGCT\",\"TCGA-THCA\",\"TCGA-THYM\",\"TCGA-UCEC\",\"TCGA-UCS\",\"TCGA-UVM\"]\n",
    "\n",
    "for cancer_type in range(len(names)):\n",
    "    ev_ = []\n",
    "    splits = 5\n",
    "    best_cindex = 0\n",
    "    for fold in range(splits):\n",
    "\n",
    "        # Censored split\n",
    "        n = len(censored_index)\n",
    "        index = np.arange(n)\n",
    "        i = n // 5\n",
    "        np.random.seed(seed=0)\n",
    "        np.random.shuffle(index)\n",
    "        if fold < 4:\n",
    "            ctest_idx = index[fold * i: fold * i + i]\n",
    "            ctrain_idx = np.concatenate((index[:fold * i],index[fold * i + i:]))\n",
    "        else:\n",
    "            ctest_idx = index[fold * i:]\n",
    "            ctrain_idx = index[:fold * i]\n",
    "        ctrain_n = len(ctrain_idx)\n",
    "        cvalid_n = ctrain_n // 10\n",
    "        cvalid_idx = ctrain_idx[:cvalid_n]\n",
    "        ctrain_idx = ctrain_idx[cvalid_n:]\n",
    "\n",
    "        # Uncensored split\n",
    "        n = len(uncensored_index)\n",
    "        index = np.arange(n)\n",
    "        i = n // 5\n",
    "        np.random.seed(seed=0)\n",
    "        np.random.shuffle(index)\n",
    "        if fold < 4:\n",
    "            utest_idx = index[fold * i: fold * i + i]\n",
    "            utrain_idx = np.concatenate((index[:fold * i],index[fold * i + i:]))\n",
    "        else:\n",
    "            utest_idx = index[fold * i:]\n",
    "            utrain_idx = index[:fold * i]\n",
    "        utrain_n = len(utrain_idx)\n",
    "        uvalid_n = utrain_n // 10\n",
    "        uvalid_idx = utrain_idx[:uvalid_n]\n",
    "        utrain_idx = utrain_idx[uvalid_n:]\n",
    "\n",
    "\n",
    "        train_idx = np.concatenate((\n",
    "            censored_index[ctrain_idx], uncensored_index[utrain_idx]))\n",
    "        np.random.seed(seed=0)\n",
    "        np.random.shuffle(train_idx)\n",
    "        valid_idx = np.concatenate((\n",
    "            censored_index[cvalid_idx], uncensored_index[uvalid_idx]))\n",
    "        np.random.seed(seed=0)\n",
    "        np.random.shuffle(valid_idx)\n",
    "        test_idx = np.concatenate((\n",
    "            censored_index[ctest_idx], uncensored_index[utest_idx]))\n",
    "        np.random.seed(seed=0)\n",
    "        np.random.shuffle(test_idx)\n",
    "\n",
    "\n",
    "        train_data = dataset[train_idx]\n",
    "        train_data = min_max_scaler.fit_transform(train_data)\n",
    "        train_labels_days = labels_days[train_idx]\n",
    "        train_labels_surv = labels_surv[train_idx]\n",
    "        train_labels = (train_labels_days, train_labels_surv)\n",
    "\n",
    "        val_data = dataset[valid_idx]\n",
    "        val_data = min_max_scaler.transform(val_data)\n",
    "        val_labels_days = labels_days[valid_idx]\n",
    "        val_labels_surv = labels_surv[valid_idx]\n",
    "        test_data = dataset[test_idx]\n",
    "        test_data = min_max_scaler.transform(test_data)\n",
    "        test_labels_days = labels_days[test_idx]\n",
    "        test_labels_surv = labels_surv[test_idx]\n",
    "        val_labels = (val_labels_days, val_labels_surv)\n",
    "\n",
    "\n",
    "        callbacks = [tt.callbacks.EarlyStopping()]\n",
    "        batch_size = 16\n",
    "        epochs = 100\n",
    "        val = (val_data, val_labels)\n",
    "        log = model.fit(\n",
    "            train_data, train_labels, batch_size, epochs, callbacks, False,\n",
    "            val_data=val,\n",
    "            val_batch_size=batch_size)\n",
    "        train = train_data, train_labels\n",
    "        # Compute the evaluation measurements\n",
    "        _ = model.compute_baseline_hazards(*train)\n",
    "        surv = model.predict_surv_df(test_data)\n",
    "        ev = EvalSurv(surv, test_labels_days, test_labels_surv)\n",
    "        ev_.append(ev.concordance_td())\n",
    "\n",
    "        if ev.concordance_td() > best_cindex:\n",
    "            best_cindex = ev.concordance_td()\n",
    "            with open('test'+str(fold+1)+'.pkl','wb') as f:\n",
    "                pickle.dump(test_data, f)\n",
    "\n",
    "            with open('test_labels_days'+str(fold+1)+'.pkl','wb') as f:\n",
    "                pickle.dump(test_labels_days, f)\n",
    "\n",
    "            with open('test_labels_surv'+str(fold+1)+'.pkl','wb') as f:\n",
    "                pickle.dump(test_labels_surv, f)\n",
    "\n",
    "    print(names[cancer_type])            \n",
    "    print(str(statistics.mean(ev_))+\"[\"+str(min(ev_))+\"-\"+str(max(ev_))+\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a8c3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
